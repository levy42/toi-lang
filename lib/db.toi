import btree, binary, string, table, uuid

SEP = string.char(31)
HI = string.char(255)
QUERY_OPTION_KEYS = {"order_by", "limit", "offset", "select"}

fn encode_key_part(value)
  if istype(value, 'number')
    return "n:" + str(value)
  return "s:" + str(value)

fn secondary_key(index_value, primary_value)
  return encode_key_part(index_value) + SEP + encode_key_part(primary_value)

fn secondary_min(index_value)
  return encode_key_part(index_value) + SEP

fn secondary_max(index_value)
  return encode_key_part(index_value) + SEP + HI

fn open(base_path)
  db = {
    base_path = base_path,
    tables = {},
    closed = false
  }

  fn ensure_open(self)
    if self.closed
      error("db: database is closed")

  fn decode_record(blob)
    if not blob
      return nil
    return binary.unpack(blob)

  fn encode_record(row)
    return binary.pack(row)

  fn sanitize_row(row)
    out = {}
    for k, v in row
      private = type(k) == "string" and #k >= 2 and k[..2] == "__"
      if not private
        out[k] = v
    return out

  fn ensure_schema(schema)
    if schema.__indexes == nil
      schema.__indexes = {}

    normalized_indexes = {}
    for idx in schema.__indexes
      if type(idx) == "string"
        normalized_indexes <+ {name = idx, field = idx, unique = false}
      else
        idx_field = idx.field == nil ? idx.name : idx.field
        idx_name = idx.name == nil ? idx_field : idx.name
        normalized_indexes <+ {name = idx_name, field = idx_field, unique = idx.unique}

    return {
      name = schema.__name,
      model = schema,
      primary_key = "id",
      indexes = normalized_indexes
    }

  fn save_secondary_indexes(table_state, row)
    pk_value = row[table_state.primary_key]

    for index_name, idx_state in table_state.indexes
      idx_value = row[idx_state.spec.field]
      if idx_value != nil
        k = secondary_key(idx_value, pk_value)
        idx_state.tree.put(k, pk_value)

  fn remove_secondary_indexes(table_state, row)
    pk_value = row[table_state.primary_key]

    for index_name, idx_state in table_state.indexes
      idx_value = row[idx_state.spec.field]
      if idx_value != nil
        k = secondary_key(idx_value, pk_value)
        idx_state.tree.delete(k)

  fn load_by_index_value(table_state, idx_state, index_value, limit = nil)
    min_key = secondary_min(index_value)
    max_key = secondary_max(index_value)
    rows = limit == nil ? idx_state.tree.range(min_key, max_key) : idx_state.tree.range(min_key, max_key, limit)
    out = {}
    for entry in rows
      pk = entry.value
      blob = table_state.primary.get(pk)
      if blob
        out <+ decode_record(blob)
    return out

  fn load_by_index_range(table_state, idx_state, min_key, max_key, limit = nil)
    rows = limit == nil ? idx_state.tree.range(min_key, max_key) : idx_state.tree.range(min_key, max_key, limit)
    out = {}
    for entry in rows
      pk = entry.value
      blob = table_state.primary.get(pk)
      if blob
        out <+ decode_record(blob)
    return out

  fn enforce_unique_indexes(table_state, row, exclude_pk = nil)
    for idx_name, idx_state in table_state.indexes
      if idx_state.spec.unique
        idx_value = row[idx_state.spec.field]
        if idx_value == nil
          continue

        rows = idx_state.tree.range(secondary_min(idx_value), secondary_max(idx_value), 2)
        for entry in rows
          existing_pk = entry.value
          if exclude_pk == nil or existing_pk != exclude_pk
            error("db.put: unique index '" + idx_name + "' violation on table '" + table_state.name + "'")

  fn get_index_for_field(table_state, field_name)
    idx_state = table_state.indexes[field_name]
    if idx_state
      return idx_state

    for idx_name, idx in table_state.indexes
      if idx.spec.field == field_name
        return idx
    return nil

  fn parse_condition_key(key)
    pos = string.find(key, "__")
    if pos == nil
      return {field = key, op = "eq"}

    split_start = pos
    if string.sub(key, pos, pos + 1) != "__"
      split_start = pos - 1

    return {
      field = string.sub(key, 1, split_start - 1),
      op = string.sub(key, split_start + 2)
    }

  fn is_query_option_key(key)
    return QUERY_OPTION_KEYS has key

  fn list_contains(values, wanted)
    for v in values
      if v == wanted
        return true
    return false

  fn eval_condition(actual, op, expected)
    match op
      case "eq"
        return actual == expected
      case "ne"
        return actual != expected
      case "gt"
        return actual != nil and expected != nil and actual > expected
      case "gte"
        return actual != nil and expected != nil and actual >= expected
      case "lt"
        return actual != nil and expected != nil and actual < expected
      case "lte"
        return actual != nil and expected != nil and actual <= expected
      case "startswith"
        return #expected <= #actual and actual[..#expected] == expected
      case "contains"
        return string.find(actual, expected) != nil
      case "in"
        return list_contains(expected, actual)
      else
        return false

  fn row_matches_query(row, query)
    for k, expected in query
      if k != "all" and k != "any" and not is_query_option_key(k)
        parsed = parse_condition_key(k)
        if not eval_condition(row[parsed.field], parsed.op, expected)
          return false

    if query.all != nil
      for clause in query.all
        if not row_matches_query(row, clause)
          return false

    if query.any != nil
      any_ok = false
      for clause in query.any
        if row_matches_query(row, clause)
          any_ok = true
          break
      if not any_ok
        return false

    return true

  fn intersect_rows(left, right)
    if left == nil
      return right

    keep = {}
    for row in right
      keep[row.id] = true

    out = {}
    for row in left
      if keep[row.id]
        out <+ row
    return out

  fn union_rows(left, right)
    if left == nil
      return right
    if right == nil
      return left

    seen = {}
    out = {}
    for row in left
      seen[row.id] = true
      out <+ row
    for row in right
      if not seen[row.id]
        seen[row.id] = true
        out <+ row
    return out

  fn sort_rows(rows, order_by)
    if not order_by
      return rows

    desc = order_by[1] == "-"
    field = desc ? order_by[2..] : order_by
    table.sort(rows, fn(a, b)
      av = a[field]
      bv = b[field]
      return desc ? av > bv : av < bv
    )
    return rows

  fn apply_select(rows, select)
    if not select
      return rows

    out = {}
    for row in rows
      projected = {}
      for field_name in select
        projected[field_name] = row[field_name]
      out <+ projected
    return out

  fn apply_offset_limit(rows, offset, limit)
    if offset == nil and limit == nil
      return rows
    if offset == nil
      return rows[..limit]
    start = offset + 1
    if limit == nil
      return rows[start..]
    return rows[start..start + limit - 1]

  fn can_use_index_for_condition(op, expected)
    match op
      case "eq"
        return expected != nil
      case "in"
        if expected == nil
          return false
        return true
      case "gte"
        return expected != nil
      case "gt"
        return expected != nil
      case "lte"
        return expected != nil
      case "lt"
        return expected != nil
      case "startswith"
        return expected != nil
      else
        return false

  fn index_rows_for_condition(table_state, idx_state, op, expected)
    match op
      case "eq"
        return load_by_index_value(table_state, idx_state, expected)
      case "in"
        unioned = nil
        for v in expected
          rows = load_by_index_value(table_state, idx_state, v)
          unioned = union_rows(unioned, rows)
        return unioned == nil ? {} : unioned
      case "gte"
        return load_by_index_range(table_state, idx_state, secondary_min(expected), nil)
      case "gt"
        return load_by_index_range(table_state, idx_state, secondary_max(expected), nil)
      case "lte"
        return load_by_index_range(table_state, idx_state, nil, secondary_max(expected))
      case "lt"
        return load_by_index_range(table_state, idx_state, nil, secondary_min(expected))
      case "startswith"
        prefix = "s:" + expected
        return load_by_index_range(table_state, idx_state, prefix, prefix + HI)
      else
        return nil

  fn table_state_for(self, table_name)
    return self.tables[table_name]

  fn build_query_plan(table_state, query)
    plan = {
      used_indexes = {},
      post_filters = {},
      has_group_logic = query.any != nil or query.all != nil,
      full_scan = false,
      index_accelerated = false,
      order_by = query.order_by,
      limit = query.limit,
      offset = query.offset,
      select = query.select
    }

    if plan.has_group_logic
      plan.full_scan = true
      return plan

    for k, expected in query
      if k != "all" and k != "any" and not is_query_option_key(k)
        parsed = parse_condition_key(k)
        idx_state = get_index_for_field(table_state, parsed.field)
        if idx_state != nil and expected != nil and can_use_index_for_condition(parsed.op, expected)
          plan.used_indexes <+ {
            field = parsed.field,
            op = parsed.op,
            index = idx_state.name
          }
        else
          plan.post_filters <+ {
            field = parsed.field,
            op = parsed.op
          }

    plan.index_accelerated = #plan.used_indexes > 0
    plan.full_scan = not plan.index_accelerated
    return plan

  fn pick_index_candidates(table_state, query)
    if query.any != nil or query.all != nil
      return nil

    candidates = nil
    for k, expected in query
      if k != "all" and k != "any" and not is_query_option_key(k)
        parsed = parse_condition_key(k)
        idx_state = get_index_for_field(table_state, parsed.field)
        if idx_state == nil or expected == nil
          continue
        if not can_use_index_for_condition(parsed.op, expected)
          continue
        rows = index_rows_for_condition(table_state, idx_state, parsed.op, expected)
        if rows != nil
          candidates = intersect_rows(candidates, rows)
    return candidates

  fn make_table_proxy(self, table_state)
    proxy = {
      name = table_state.name,
      schema = table_state.model
    }

    proxy.put = fn(row)
      ensure_open(self)
      checked = table_state.model.check(row)
      clean = sanitize_row(checked)

      pk_field = table_state.primary_key
      pk_value = clean[pk_field]
      encode_key_part(pk_value)

      old_blob = table_state.primary.get(pk_value)
      enforce_unique_indexes(table_state, clean, pk_value)
      if old_blob != nil
        old_row = decode_record(old_blob)
        remove_secondary_indexes(table_state, old_row)

      table_state.primary.put(pk_value, encode_record(clean))
      save_secondary_indexes(table_state, clean)
      return clean

    proxy.get = fn(primary_key)
      ensure_open(self)
      encode_key_part(primary_key)
      blob = table_state.primary.get(primary_key)
      return decode_record(blob)

    proxy.delete = fn(primary_key)
      ensure_open(self)
      encode_key_part(primary_key)

      old_blob = table_state.primary.get(primary_key)
      if old_blob == nil
        return false

      old_row = decode_record(old_blob)
      remove_secondary_indexes(table_state, old_row)
      table_state.primary.delete(primary_key)
      return true

    proxy.filter = fn(opts = nil)
      ensure_open(self)
      opts = opts or {}

      candidates = pick_index_candidates(table_state, opts)

      if candidates == nil
        entries = table_state.primary.range(nil, nil)
        candidates = {}
        for entry in entries
          candidates <+ decode_record(entry.value)

      out = {}
      for row in candidates
        if row_matches_query(row, opts)
          out <+ row
      out = sort_rows(out, opts.order_by)
      out = apply_offset_limit(out, opts.offset, opts.limit)
      out = apply_select(out, opts.select)
      return out

    proxy.first = fn(opts = nil)
      rows = proxy.filter(opts)
      if #rows == 0
        return nil
      return rows[1]

    proxy.count = fn(opts = nil)
      return #proxy.filter(opts)

    proxy.exists = fn(opts = nil)
      return proxy.first(opts) != nil

    proxy.explain = fn(opts = nil)
      ensure_open(self)
      opts = opts or {}
      return build_query_plan(table_state, opts)

    proxy.delete_where = fn(opts = nil)
      ensure_open(self)
      rows = proxy.filter(opts)
      deleted = 0
      for row in rows
        if proxy.delete(row.id)
          deleted = deleted + 1
      return deleted

    proxy.update_where = fn(opts, patch)
      ensure_open(self)
      rows = proxy.filter(opts)
      updated = 0
      for row in rows
        delta = patch
        if istype(patch, "function")
          if not (delta:=patch(row))
            continue

        next_row = table.clone(row)
        for k, v in delta
          if k != "id"
            next_row[k] = v
        next_row.id = row.id

        proxy.put(next_row)
        updated = updated + 1

      return updated

    return proxy

  db.create_table = fn(self, schema)
    ensure_open(self)

    normalized = ensure_schema(schema)
    table_name = normalized.name

    existing = self.tables[table_name]
    if existing
      return existing.proxy

    primary_path = self.base_path + "_" + table_name + ".db"
    table_state = {
      name = table_name,
      model = normalized.model,
      primary_key = normalized.primary_key,
      primary = btree.open(primary_path),
      indexes = {}
    }

    for idx in normalized.indexes
      idx_name = idx.name == nil ? idx.field : idx.name
      idx_path = self.base_path + "_" + table_name + "__idx_" + idx_name + ".db"
      table_state.indexes[idx_name] = {
        name = idx_name,
        spec = idx,
        tree = btree.open(idx_path)
      }

    proxy = make_table_proxy(self, table_state)
    table_state.proxy = proxy

    self.tables[table_name] = table_state
    self[table_name] = proxy
    return proxy

  db.add = fn(self, record)
    ensure_open(self)
    schema = record.__model
    proxy = self.create_table(schema)
    row = {}
    for k, v in record
      row[k] = v
    row.id = uuid.uid()
    return proxy.put(row)

  -- Backward-compatible API
  db.put = fn(self, table_name, row)
    state = table_state_for(self, table_name)
    return state.proxy.put(row)

  db.get = fn(self, table_name, primary_key)
    state = table_state_for(self, table_name)
    return state.proxy.get(primary_key)

  db.delete = fn(self, table_name, primary_key)
    state = table_state_for(self, table_name)
    return state.proxy.delete(primary_key)

  db.close = fn(self)
    if self.closed return true
    for table_name, table_state in self.tables
      table_state.primary.close()
      for idx_name, idx_state in table_state.indexes
        idx_state.tree.close()
    self.closed = true
    return true

  return db

return {
  open = open
}
